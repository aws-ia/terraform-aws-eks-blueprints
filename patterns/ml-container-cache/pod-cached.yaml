apiVersion: v1
kind: Pod
metadata:
  name: cached
spec:
  containers:
    - name: example
      image: nvcr.io/nvidia/pytorch:24.07-py3
      command: ['python3']
      args:
        [
          '-c',
          'import torch; print(torch.cuda.is_available()); print(torch.cuda.device_count())',
        ]
      resources:
        limits:
          nvidia.com/gpu: '1'
  nodeSelector:
    ml-container-cache: 'true'
  tolerations:
    - key: 'nvidia.com/gpu'
      operator: 'Exists'
      effect: 'NoSchedule'
